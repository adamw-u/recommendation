{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lr不能做回归，简单看下xgboost生成特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/baogong/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./util/')\n",
    "from utils import load_data\n",
    "\n",
    "users, movies, ratings = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/baogong/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: DataConversionWarning: Data with input dtype int32, float64 were all converted to float64 by the scale function.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "data1 = pd.merge(ratings.drop(columns = ['timestamp'],axis = 1), movies, how = 'left', on = 'movieid')\n",
    "data = pd.merge(data1, users, how = 'left', on = 'userid')\n",
    "\n",
    "X = data.drop(columns = ['userid', 'movieid', 'genres', 'title', 'rating'])\n",
    "Y = data['rating'].values\n",
    "\n",
    "from sklearn import preprocessing\n",
    "X_norm = preprocessing.scale(X)\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(X_norm, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.85, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=400,\n",
       "       n_jobs=12, nthread=None, objective='multi:softprob', random_state=1,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=0.85)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "import numpy as np\n",
    "m = XGBClassifier(random_state=1, max_depth=5, min_child_weight=1, learning_rate=0.1, subsample=0.85,\n",
    "                      colsample_bytree=0.85, n_estimators=400, n_jobs=12, objective=\"binary:logistic\")\n",
    "m.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_train_x = m.apply(train_x)\n",
    "xgb_test_x = m.apply(test_x)\n",
    "\n",
    "xgb_max = float(xgb_train_x.max())\n",
    "train_x_new = np.concatenate((train_x, xgb_train_x/xgb_max),axis = 1)\n",
    "test_x_new = np.concatenate((test_x, xgb_test_x/xgb_max),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = train_x_new.shape[1]\n",
    "learning_rate = 0.01\n",
    "\n",
    "linear_input = tf.keras.layers.Input(shape = (input_shape,), name = \"linear\")\n",
    "outputs = tf.keras.layers.Dense(1, name = \"outputs\")(linear_input)\n",
    "\n",
    "model = tf.keras.Model(inputs = [linear_input], outputs = [outputs])\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate = 0.001)\n",
    "model.compile(loss='mean_squared_error',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['mean_absolute_error', 'mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 750156 samples, validate on 250053 samples\n",
      "Epoch 1/50\n",
      "750156/750156 [==============================] - 10s 13us/sample - loss: 1.4688 - mean_absolute_error: 0.9765 - mean_squared_error: 1.4688 - val_loss: 1.6022 - val_mean_absolute_error: 1.0627 - val_mean_squared_error: 1.6022\n",
      "Epoch 2/50\n",
      "750156/750156 [==============================] - 10s 13us/sample - loss: 1.4677 - mean_absolute_error: 0.9764 - mean_squared_error: 1.4677 - val_loss: 1.6746 - val_mean_absolute_error: 1.0002 - val_mean_squared_error: 1.6746\n",
      "Epoch 3/50\n",
      "750156/750156 [==============================] - 10s 13us/sample - loss: 1.4685 - mean_absolute_error: 0.9764 - mean_squared_error: 1.4685 - val_loss: 1.2600 - val_mean_absolute_error: 0.9355 - val_mean_squared_error: 1.2600\n",
      "Epoch 4/50\n",
      "750156/750156 [==============================] - 10s 13us/sample - loss: 1.4672 - mean_absolute_error: 0.9766 - mean_squared_error: 1.4672 - val_loss: 1.2645 - val_mean_absolute_error: 0.8782 - val_mean_squared_error: 1.2645\n",
      "Epoch 5/50\n",
      "750156/750156 [==============================] - 10s 13us/sample - loss: 1.4678 - mean_absolute_error: 0.9760 - mean_squared_error: 1.4678 - val_loss: 1.3975 - val_mean_absolute_error: 0.9080 - val_mean_squared_error: 1.3975\n",
      "Epoch 6/50\n",
      "750156/750156 [==============================] - 9s 13us/sample - loss: 1.4685 - mean_absolute_error: 0.9765 - mean_squared_error: 1.4685 - val_loss: 1.7071 - val_mean_absolute_error: 1.1027 - val_mean_squared_error: 1.7071\n",
      "Epoch 7/50\n",
      "750156/750156 [==============================] - 9s 13us/sample - loss: 1.4677 - mean_absolute_error: 0.9765 - mean_squared_error: 1.4677 - val_loss: 1.4894 - val_mean_absolute_error: 0.9375 - val_mean_squared_error: 1.4894\n",
      "Epoch 8/50\n",
      "750156/750156 [==============================] - 10s 13us/sample - loss: 1.4653 - mean_absolute_error: 0.9749 - mean_squared_error: 1.4653 - val_loss: 1.1802 - val_mean_absolute_error: 0.8895 - val_mean_squared_error: 1.1802\n",
      "Epoch 9/50\n",
      "750156/750156 [==============================] - 10s 13us/sample - loss: 1.4655 - mean_absolute_error: 0.9752 - mean_squared_error: 1.4655 - val_loss: 1.5740 - val_mean_absolute_error: 0.9662 - val_mean_squared_error: 1.5740\n",
      "Epoch 10/50\n",
      "750156/750156 [==============================] - 10s 13us/sample - loss: 1.4645 - mean_absolute_error: 0.9752 - mean_squared_error: 1.4645 - val_loss: 1.2280 - val_mean_absolute_error: 0.8735 - val_mean_squared_error: 1.2280\n",
      "Epoch 11/50\n",
      "750156/750156 [==============================] - 10s 13us/sample - loss: 1.4636 - mean_absolute_error: 0.9751 - mean_squared_error: 1.4636 - val_loss: 2.0858 - val_mean_absolute_error: 1.2408 - val_mean_squared_error: 2.0858\n",
      "Epoch 12/50\n",
      "750156/750156 [==============================] - 10s 13us/sample - loss: 1.4645 - mean_absolute_error: 0.9760 - mean_squared_error: 1.4645 - val_loss: 1.5643 - val_mean_absolute_error: 1.0498 - val_mean_squared_error: 1.5643\n",
      "Epoch 13/50\n",
      "750156/750156 [==============================] - 10s 13us/sample - loss: 1.4621 - mean_absolute_error: 0.9748 - mean_squared_error: 1.4621 - val_loss: 1.3217 - val_mean_absolute_error: 0.9588 - val_mean_squared_error: 1.3217\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1d406ef198>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "model.fit(\n",
    "    train_x_new, train_y,\n",
    "    epochs=EPOCHS, \n",
    "    validation_data=(test_x_new, test_y),\n",
    "    batch_size=256, shuffle=True,\n",
    "    callbacks = [early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
