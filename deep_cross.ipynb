{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "论文地址：https://arxiv.org/pdf/1708.05123.pdf  \n",
    "<img src=\"./images/deep_cross.png\" style=\"width:500;height:400px;\">  \n",
    "其实dnn结构相对是比较熟悉了，主要是cross这个结构：\n",
    "$$\\mathbf{x}_{l+1}=\\mathbf{x}_{0} \\mathbf{x}_{l}^{T} \\mathbf{w}_{l}+\\mathbf{b}_{l}+\\mathbf{x}_{l}=f\\left(\\mathbf{x}_{l}, \\mathbf{w}_{l}, \\mathbf{b}_{l}\\right)+\\mathbf{x}_{l}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./util/')\n",
    "from utils import load_data_embdding \n",
    "\n",
    "users, movies, ratings = load_data_embdding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.merge(ratings.drop(columns = ['timestamp'],axis = 1), movies, how = 'left', on = 'movieid')\n",
    "data = pd.merge(data1, users, how = 'left', on = 'userid')\n",
    "\n",
    "X = data.drop(columns = ['userid', 'movieid', 'title', 'rating'])\n",
    "Y = data['rating'].values\n",
    "#genres, gender, age, occupationid四个需要embedding的特征，可以分别emb也可以合并以后emb，这里分别做emb\n",
    "set_genres = []\n",
    "for i in movies.index:\n",
    "    set_genres += movies['genres'].iloc[i]\n",
    "set_genres = list(set(set_genres))\n",
    "dic_genres = dict([(j, i) for i,j in enumerate(set_genres)])\n",
    "dic_genres['UNK'] = len(dic_genres)\n",
    "X['genres'] = X['genres'].apply(lambda x: [dic_genres[i] for i in x])\n",
    "x_genres = tf.keras.preprocessing.sequence.pad_sequences(list(X['genres'].values),\n",
    "                                                        value = dic_genres['UNK'],\n",
    "                                                        padding = 'post',\n",
    "                                                        maxlen = 6)\n",
    "\n",
    "\n",
    "dic_gender = {'F':0, 'M':1}\n",
    "X['gender'] = X['gender'].apply(lambda x: [dic_gender[i] for i in x])\n",
    "dic_age = {1:0, 56:1, 25:2, 45:3, 50:4, 35:5, 18:6}\n",
    "X['age'] = X['age'].apply(lambda x: [dic_age[x]])\n",
    "list_occ = list(pd.unique(data['occupationid']))\n",
    "dic_occ = dict([(j, i) for i,j in enumerate(list_occ)])\n",
    "X['occupationid'] = X['occupationid'].apply(lambda x: [dic_occ[x]])\n",
    "\n",
    "x_gender = list(X['gender'].values)\n",
    "x_age = list(X['age'].values)\n",
    "x_occupationid = list(X['occupationid'].values)\n",
    "\n",
    "\n",
    "train_x_genres, test_x_genres, train_y, test_y = train_test_split(np.array(x_genres), Y, random_state=11)\n",
    "train_x_gender, test_x_gender = train_test_split(np.array(x_gender), random_state=11)\n",
    "train_x_age, test_x_age = train_test_split(np.array(x_age), random_state=11)\n",
    "train_x_occupationid, test_x_occupationid = train_test_split(np.array(x_occupationid), random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class crossNet(Layer):\n",
    "    def __init__(self, l2, layer_num, **kwargs):\n",
    "        self.l2 = l2\n",
    "        self.layer_num = layer_num\n",
    "        super(crossNet, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        input_dim = input_shape[-1]\n",
    "        self.w = [self.add_weight(name='kernel' + str(i),\n",
    "                                        shape=(input_dim, 1),\n",
    "                                        initializer='glorot_uniform',\n",
    "                                        regularizer=l2(self.l2),\n",
    "                                        trainable=True) for i in range(self.layer_num)]\n",
    "        self.b = [self.add_weight(name='bias' + str(i),\n",
    "                                     shape=(input_dim, 1),\n",
    "                                     initializer='Zeros',\n",
    "                                     trainable=True) for i in range(self.layer_num)]\n",
    "\n",
    "        super(crossNet, self).build(input_shape)\n",
    "    \n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        x0 = inputs\n",
    "        input_dim = x0.shape[1]\n",
    "        x0 = tf.reshape(x0, [-1, input_dim, 1]) #之所以改成三维就是为了在多次运算后batch维度的不变\n",
    "        x_l = x0                                                            #(None, input_dim)\n",
    "        for i in range(self.layer_num):\n",
    "            xw_l = tf.matmul(tf.transpose(self.w[i]), x_l) \n",
    "            #(1,input_dim) * (None, input_dim, 1) -> (None, 1, 1)\n",
    "            x_l = tf.matmul(x0, xw_l)  + self.b[i] + x_l #(None, input_dim, 1)\n",
    "            #张量相乘，比如三维，第一维维度要一致，后面两维满足矩阵乘法，相加后面两维要一致\n",
    "            #3维与2维，乘法后面两维满足矩阵乘法，相加后面两维要一致\n",
    "        return tf.reshape(x_l, (-1,input_dim))\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None,self.units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\mathbf{x}_{l+1}=\\mathbf{x}_{0} \\mathbf{x}_{l}^{T} \\mathbf{w}_{l}+\\mathbf{b}_{l}+\\mathbf{x}_{l}=f\\left(\\mathbf{x}_{l}, \\mathbf{w}_{l}, \\mathbf{b}_{l}\\right)+\\mathbf{x}_{l}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = tf.constant([[[1.,2,3],[1,2,1],[1,2,1]],[[1,2,3],[1,2,1],[1,2,1]]])\n",
    "m2 = tf.constant([[1.,3,3],[2,1,3]])\n",
    "\n",
    "tf.matmul(tf.ones((3,1)),tf.ones((2,1,3))) \n",
    "tf.matmul(tf.ones((2,3,3)),tf.ones((3,1))) + tf.ones((3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=4590, shape=(2, 1, 1), dtype=float32, numpy=\n",
       "array([[[3.]],\n",
       "\n",
       "       [[3.]]], dtype=float32)>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tf.tensordot(tf.ones((2,3,3)),tf.ones((2,3)),(1,0)) \n",
    "tf.tensordot(tf.expand_dims(tf.ones((2,3)), axis=2),tf.ones((3,1)),axes=(1, 0))\n",
    "#tf.matmul(tf.ones((2,3,1)),tf.ones((2,1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_genres = keras.layers.Input(shape=(6,), name=\"genres\")  \n",
    "embedding_genres = keras.layers.Embedding(output_dim=16, input_dim=len(dic_genres), input_length=6)(input_genres)\n",
    "\n",
    "input_gender = keras.layers.Input(shape=(1,), name=\"gender\")  \n",
    "embedding_gender = keras.layers.Embedding(output_dim=16, input_dim=2, input_length=1)(input_gender)\n",
    "\n",
    "input_age = keras.layers.Input(shape=(1,), name=\"age\")  \n",
    "embedding_age = keras.layers.Embedding(output_dim=16, input_dim=7, input_length=1)(input_age)\n",
    "\n",
    "input_occ = keras.layers.Input(shape=(1,), name=\"occupationid\")  \n",
    "embedding_occ = keras.layers.Embedding(output_dim=16, input_dim=21, input_length=1)(input_occ)\n",
    "\n",
    "embedding_combine = keras.layers.concatenate(inputs=[embedding_genres, embedding_gender, embedding_age,\n",
    "                                                    embedding_occ], axis=1)\n",
    "embedding_combine = keras.layers.GlobalAveragePooling1D()(embedding_combine) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "##cross_net\n",
    "cn_layer = crossNet(0.001, 4)(embedding_combine)\n",
    "cn_layer = keras.layers.Dense(1)(cn_layer)\n",
    "##dnn\n",
    "dnn_layer = keras.layers.Dense(64, activation = 'relu')(embedding_combine)\n",
    "dnn_layer = keras.layers.BatchNormalization()(dnn_layer)\n",
    "dnn_layer = keras.layers.Dense(32, activation = 'relu')(dnn_layer)\n",
    "dnn_layer = keras.layers.BatchNormalization()(dnn_layer)\n",
    "dnn_layer = keras.layers.Dense(1)(dnn_layer)\n",
    "##deepfm\n",
    "outputs = keras.layers.average([cn_layer, dnn_layer])  #因为是做回归，就用了average，分类的话得add后再接Activation\n",
    "\n",
    "optimizer = keras.optimizers.RMSprop(learning_rate = 0.001)\n",
    "model = tf.keras.Model(inputs = [input_genres, input_gender, input_age, input_occ], outputs = [outputs])\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['mean_absolute_error', 'mean_squared_error'],\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 750156 samples, validate on 250053 samples\n",
      "Epoch 1/100\n",
      "750080/750156 [============================>.] - ETA: 0s - loss: 1.4316 - mean_absolute_error: 0.9487 - mean_squared_error: 1.4281\n",
      "Epoch 00001: val_loss improved from inf to 1.17800, saving model to ./model/deepcross.h5\n",
      "750156/750156 [==============================] - 14s 19us/sample - loss: 1.4315 - mean_absolute_error: 0.9487 - mean_squared_error: 1.4280 - val_loss: 1.1780 - val_mean_absolute_error: 0.8751 - val_mean_squared_error: 1.1764\n",
      "Epoch 2/100\n",
      "747520/750156 [============================>.] - ETA: 0s - loss: 1.1644 - mean_absolute_error: 0.8787 - mean_squared_error: 1.1634\n",
      "Epoch 00002: val_loss improved from 1.17800 to 1.16190, saving model to ./model/deepcross.h5\n",
      "750156/750156 [==============================] - 12s 16us/sample - loss: 1.1642 - mean_absolute_error: 0.8786 - mean_squared_error: 1.1632 - val_loss: 1.1619 - val_mean_absolute_error: 0.8817 - val_mean_squared_error: 1.1613\n",
      "Epoch 3/100\n",
      "750080/750156 [============================>.] - ETA: 0s - loss: 1.1586 - mean_absolute_error: 0.8764 - mean_squared_error: 1.1582\n",
      "Epoch 00003: val_loss improved from 1.16190 to 1.16145, saving model to ./model/deepcross.h5\n",
      "750156/750156 [==============================] - 12s 17us/sample - loss: 1.1586 - mean_absolute_error: 0.8764 - mean_squared_error: 1.1582 - val_loss: 1.1615 - val_mean_absolute_error: 0.8812 - val_mean_squared_error: 1.1612\n",
      "Epoch 4/100\n",
      "748800/750156 [============================>.] - ETA: 0s - loss: 1.1554 - mean_absolute_error: 0.8748 - mean_squared_error: 1.1552\n",
      "Epoch 00004: val_loss improved from 1.16145 to 1.16042, saving model to ./model/deepcross.h5\n",
      "750156/750156 [==============================] - 12s 16us/sample - loss: 1.1554 - mean_absolute_error: 0.8748 - mean_squared_error: 1.1552 - val_loss: 1.1604 - val_mean_absolute_error: 0.8736 - val_mean_squared_error: 1.1603\n",
      "Epoch 5/100\n",
      "747520/750156 [============================>.] - ETA: 0s - loss: 1.1539 - mean_absolute_error: 0.8738 - mean_squared_error: 1.1538\n",
      "Epoch 00005: val_loss improved from 1.16042 to 1.15155, saving model to ./model/deepcross.h5\n",
      "750156/750156 [==============================] - 12s 16us/sample - loss: 1.1538 - mean_absolute_error: 0.8737 - mean_squared_error: 1.1537 - val_loss: 1.1515 - val_mean_absolute_error: 0.8772 - val_mean_squared_error: 1.1515\n",
      "Epoch 6/100\n",
      "746752/750156 [============================>.] - ETA: 0s - loss: 1.1528 - mean_absolute_error: 0.8733 - mean_squared_error: 1.1528\n",
      "Epoch 00006: val_loss improved from 1.15155 to 1.15091, saving model to ./model/deepcross.h5\n",
      "750156/750156 [==============================] - 12s 16us/sample - loss: 1.1528 - mean_absolute_error: 0.8733 - mean_squared_error: 1.1527 - val_loss: 1.1509 - val_mean_absolute_error: 0.8692 - val_mean_squared_error: 1.1509\n",
      "Epoch 7/100\n",
      "749568/750156 [============================>.] - ETA: 0s - loss: 1.1515 - mean_absolute_error: 0.8728 - mean_squared_error: 1.1515\n",
      "Epoch 00007: val_loss did not improve from 1.15091\n",
      "750156/750156 [==============================] - 12s 16us/sample - loss: 1.1516 - mean_absolute_error: 0.8729 - mean_squared_error: 1.1515 - val_loss: 1.1565 - val_mean_absolute_error: 0.8810 - val_mean_squared_error: 1.1565\n",
      "Epoch 8/100\n",
      "747520/750156 [============================>.] - ETA: 0s - loss: 1.1505 - mean_absolute_error: 0.8724 - mean_squared_error: 1.1505\n",
      "Epoch 00008: val_loss did not improve from 1.15091\n",
      "750156/750156 [==============================] - 12s 17us/sample - loss: 1.1505 - mean_absolute_error: 0.8724 - mean_squared_error: 1.1505 - val_loss: 1.1577 - val_mean_absolute_error: 0.8757 - val_mean_squared_error: 1.1577\n",
      "Epoch 9/100\n",
      "749824/750156 [============================>.] - ETA: 0s - loss: 1.1497 - mean_absolute_error: 0.8718 - mean_squared_error: 1.1497\n",
      "Epoch 00009: val_loss did not improve from 1.15091\n",
      "750156/750156 [==============================] - 12s 17us/sample - loss: 1.1498 - mean_absolute_error: 0.8719 - mean_squared_error: 1.1498 - val_loss: 1.1594 - val_mean_absolute_error: 0.8869 - val_mean_squared_error: 1.1594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f69046f62e8>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "checkpoint_path = \"./model/deepcross.h5\"\n",
    "cp_callback = keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                                              save_weights_only=True,\n",
    "                                              save_best_only=True,\n",
    "                                              verbose=1)\n",
    "\n",
    "model.fit(\n",
    "    [train_x_genres, train_x_gender, train_x_age, train_x_occupationid], train_y,\n",
    "    epochs=100, \n",
    "    validation_data=([test_x_genres, test_x_gender, test_x_age, test_x_occupationid], test_y,),\n",
    "    batch_size=256, shuffle=True,\n",
    "    callbacks=[early_stopping, cp_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "genres (InputLayer)             [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gender (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "age (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "occupationid (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 6, 16)        304         genres[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 16)        32          gender[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 16)        112         age[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1, 16)        336         occupationid[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 9, 16)        0           embedding[0][0]                  \n",
      "                                                                 embedding_1[0][0]                \n",
      "                                                                 embedding_2[0][0]                \n",
      "                                                                 embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 16)           0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 64)           1088        global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 64)           256         dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 32)           2080        batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "cross_net_9 (crossNet)          (None, 16)           128         global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32)           128         dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            17          cross_net_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1)            33          batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_2 (Average)             (None, 1)            0           dense_8[0][0]                    \n",
      "                                                                 dense_11[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 4,514\n",
      "Trainable params: 4,322\n",
      "Non-trainable params: 192\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
