{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先上论文：https://arxiv.org/pdf/1803.05170.pdf  \n",
    "git: https://github.com/Leavingseason/xDeepFM/blob/master/exdeepfm/src/exDeepFM.py  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  tensorflow  as tf\n",
    "import numpy as np\n",
    "arr1 = tf.convert_to_tensor(np.arange(1,25).reshape(2,4,3),dtype=tf.int32)\n",
    "arr2 = tf.convert_to_tensor(np.arange(1,25).reshape(2,4,3),dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_arr1 = tf.split(arr1,[1,1,1],2)#3个（2，4，1）\n",
    "split_arr2 = tf.split(arr2,[1,1,1],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split_arr1, split_arr2\n",
    "tf.matmul(split_arr1[0],split_arr2[0],transpose_b=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = tf.matmul(split_arr1,split_arr2,transpose_b=True)#（3，2，4，4）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = tf.transpose(res,perm=[1,0,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/baogong/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./util/')\n",
    "from utils import load_data_embdding \n",
    "\n",
    "users, movies, ratings = load_data_embdding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.merge(ratings.drop(columns = ['timestamp'],axis = 1), movies, how = 'left', on = 'movieid')\n",
    "data = pd.merge(data1, users, how = 'left', on = 'userid')\n",
    "\n",
    "X = data.drop(columns = ['userid', 'movieid', 'title', 'rating'])\n",
    "Y = data['rating'].values\n",
    "#genres, gender, age, occupationid四个需要embedding的特征，可以分别emb也可以合并以后emb，这里分别做emb\n",
    "set_genres = []\n",
    "for i in movies.index:\n",
    "    set_genres += movies['genres'].iloc[i]\n",
    "set_genres = list(set(set_genres))\n",
    "dic_genres = dict([(j, i) for i,j in enumerate(set_genres)])\n",
    "dic_genres['UNK'] = len(dic_genres)\n",
    "X['genres'] = X['genres'].apply(lambda x: [dic_genres[i] for i in x])\n",
    "x_genres = tf.keras.preprocessing.sequence.pad_sequences(list(X['genres'].values),\n",
    "                                                        value = dic_genres['UNK'],\n",
    "                                                        padding = 'post',\n",
    "                                                        maxlen = 6)\n",
    "\n",
    "\n",
    "dic_gender = {'F':0, 'M':1}\n",
    "X['gender'] = X['gender'].apply(lambda x: [dic_gender[i] for i in x])\n",
    "dic_age = {1:0, 56:1, 25:2, 45:3, 50:4, 35:5, 18:6}\n",
    "X['age'] = X['age'].apply(lambda x: [dic_age[x]])\n",
    "list_occ = list(pd.unique(data['occupationid']))\n",
    "dic_occ = dict([(j, i) for i,j in enumerate(list_occ)])\n",
    "X['occupationid'] = X['occupationid'].apply(lambda x: [dic_occ[x]])\n",
    "\n",
    "x_gender = list(X['gender'].values)\n",
    "x_age = list(X['age'].values)\n",
    "x_occupationid = list(X['occupationid'].values)\n",
    "\n",
    "\n",
    "train_x_genres, test_x_genres, train_y, test_y = train_test_split(np.array(x_genres), Y, random_state=11)\n",
    "train_x_gender, test_x_gender = train_test_split(np.array(x_gender), random_state=11)\n",
    "train_x_age, test_x_age = train_test_split(np.array(x_age), random_state=11)\n",
    "train_x_occupationid, test_x_occupationid = train_test_split(np.array(x_occupationid), random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIN(Layer):\n",
    "    def __init__(self, layer_size=(128, 128), activation='relu', direct=False, l2=1e-5, **kwargs):\n",
    "        self.layer_size = layer_size\n",
    "        self.direct = direct\n",
    "        self.activation = activation\n",
    "        self.l2 = l2\n",
    "        super(CIN, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        self.field_nums = [int(input_shape[1])]\n",
    "        self.filters = []\n",
    "        self.bias = []\n",
    "        \n",
    "        for i, size in enumerate(self.layer_size):\n",
    "            \n",
    "            self.filters.append(self.add_weight(name='f_' + str(i),\n",
    "                                                shape=[1, self.field_nums[-1] * self.field_nums[0], size],\n",
    "                                                dtype=tf.float32, \n",
    "                                                initializer='glorot_uniform',\n",
    "                                                regularizer=l2(self.l2)))\n",
    "\n",
    "            self.bias.append(self.add_weight(name='bias' + str(i), shape=[size], dtype=tf.float32,\n",
    "                                             initializer='Zeros'))\n",
    "            \n",
    "            if self.direct:\n",
    "                self.field_nums.append(size)\n",
    "            else:\n",
    "                self.field_nums.append(size // 2)\n",
    "\n",
    "        self.activation_layers = [keras.layers.Activation(\n",
    "            self.activation) for _ in self.layer_size]\n",
    "\n",
    "        super(CIN, self).build(input_shape)  \n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "\n",
    "        dim = int(inputs.get_shape()[-1])#16\n",
    "        hidden_nn_layers = [inputs]\n",
    "        final_result = []\n",
    "\n",
    "        split_tensor0 = tf.split(hidden_nn_layers[0], dim * [1], 2)#16个（batch, 9, 1）\n",
    "        for idx, layer_size in enumerate(self.layer_size):\n",
    "            split_tensor = tf.split(hidden_nn_layers[-1], dim * [1], 2)\n",
    "\n",
    "            dot_result_m = tf.matmul( split_tensor0, split_tensor, transpose_b=True)#（16,batch,9,9）\n",
    "\n",
    "            dot_result_o = tf.reshape(\n",
    "                dot_result_m, shape=[dim, -1, self.field_nums[0] * self.field_nums[idx]])\n",
    "\n",
    "            dot_result = tf.transpose(dot_result_o, perm=[1, 0, 2])\n",
    "            #print (dot_result.shape, self.filters[idx].shape, self.field_nums)\n",
    "            #dot_result:[batch, dim, self.field_nums[0] * self.field_nums[idx]]\n",
    "            #filters:[1, self.field_nums[-1]* self.field_nums[0], layer_size]\n",
    "            #->curr_out:[batch, dim-1+1, layer_size]  dim维度是不变的\n",
    "            '''\n",
    "            conv1d: \n",
    "            x:[batch, in_width, in_channels]  \n",
    "            filters:[filter_width, in_channels, out_channels] \n",
    "            out:[batch, in_width-filter_width+1, out_channels]  不考虑stride和padding\n",
    "            '''\n",
    "            curr_out = tf.nn.conv1d(dot_result, filters=self.filters[idx], stride=1, padding='VALID')\n",
    "\n",
    "            curr_out = tf.nn.bias_add(curr_out, self.bias[idx])\n",
    "\n",
    "            curr_out = self.activation_layers[idx](curr_out)\n",
    "\n",
    "            curr_out = tf.transpose(curr_out, perm=[0, 2, 1])\n",
    "\n",
    "            if not self.direct:\n",
    "                if idx != len(self.layer_size) - 1:\n",
    "                    next_hidden, direct_connect = tf.split(curr_out, 2 * [layer_size // 2], 1)\n",
    "                else:\n",
    "                    direct_connect = curr_out\n",
    "                    next_hidden = 0\n",
    "            else:\n",
    "                direct_connect = curr_out\n",
    "                next_hidden = curr_out\n",
    "\n",
    "            final_result.append(direct_connect)\n",
    "            hidden_nn_layers.append(next_hidden)\n",
    "\n",
    "        result = tf.concat(final_result, axis=1)\n",
    "        result = tf.reduce_sum(result, -1)\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_genres = keras.layers.Input(shape=(6,), name=\"genres\")  \n",
    "embedding_genres = keras.layers.Embedding(output_dim=16, input_dim=len(dic_genres), input_length=6)(input_genres)\n",
    "\n",
    "input_gender = keras.layers.Input(shape=(1,), name=\"gender\")  \n",
    "embedding_gender = keras.layers.Embedding(output_dim=16, input_dim=2, input_length=1)(input_gender)\n",
    "\n",
    "input_age = keras.layers.Input(shape=(1,), name=\"age\")  \n",
    "embedding_age = keras.layers.Embedding(output_dim=16, input_dim=7, input_length=1)(input_age)\n",
    "\n",
    "input_occ = keras.layers.Input(shape=(1,), name=\"occupationid\")  \n",
    "embedding_occ = keras.layers.Embedding(output_dim=16, input_dim=21, input_length=1)(input_occ)\n",
    "\n",
    "embedding_combine = keras.layers.concatenate(inputs=[embedding_genres, embedding_gender, embedding_age,\n",
    "                                                    embedding_occ], axis=1)\n",
    "embedding_combine1 = keras.layers.GlobalAveragePooling1D()(embedding_combine) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 16, 81) (1, 81, 128) ListWrapper([9, 64, 64])\n",
      "(None, 16, 576) (1, 576, 128) ListWrapper([9, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "cin_layer = CIN(layer_size=(128, 128), activation='relu', direct=False, l2=1e-5)(embedding_combine)\n",
    "cin_layer = keras.layers.Dense(1)(cin_layer)\n",
    "#dnn\n",
    "dnn_layer = keras.layers.Dense(64, activation = 'relu')(embedding_combine1)\n",
    "dnn_layer = keras.layers.BatchNormalization()(dnn_layer)\n",
    "dnn_layer = keras.layers.Dense(32, activation = 'relu')(dnn_layer)\n",
    "dnn_layer = keras.layers.BatchNormalization()(dnn_layer)\n",
    "dnn_layer = keras.layers.Dense(1)(dnn_layer)\n",
    "##deepfm\n",
    "outputs = keras.layers.average([cin_layer, dnn_layer])  #因为是做回归，就用了average，分类的话得add后再接Activation\n",
    "\n",
    "optimizer = keras.optimizers.RMSprop(learning_rate = 0.001)\n",
    "model = tf.keras.Model(inputs = [input_genres, input_gender, input_age, input_occ], outputs = [outputs])\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['mean_absolute_error', 'mean_squared_error'],\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 750156 samples, validate on 250053 samples\n",
      "Epoch 1/100\n",
      "749824/750156 [============================>.] - ETA: 0s - loss: 1.2197 - mean_absolute_error: 0.8965 - mean_squared_error: 1.2189\n",
      "Epoch 00001: val_loss improved from inf to 1.17173, saving model to ./model/deepcin.h5\n",
      "750156/750156 [==============================] - 87s 115us/sample - loss: 1.2197 - mean_absolute_error: 0.8965 - mean_squared_error: 1.2189 - val_loss: 1.1717 - val_mean_absolute_error: 0.8846 - val_mean_squared_error: 1.1713\n",
      "Epoch 2/100\n",
      "749824/750156 [============================>.] - ETA: 0s - loss: 1.1621 - mean_absolute_error: 0.8774 - mean_squared_error: 1.1614\n",
      "Epoch 00002: val_loss improved from 1.17173 to 1.15612, saving model to ./model/deepcin.h5\n",
      "750156/750156 [==============================] - 84s 112us/sample - loss: 1.1621 - mean_absolute_error: 0.8774 - mean_squared_error: 1.1614 - val_loss: 1.1561 - val_mean_absolute_error: 0.8746 - val_mean_squared_error: 1.1554\n",
      "Epoch 3/100\n",
      "749824/750156 [============================>.] - ETA: 0s - loss: 1.1550 - mean_absolute_error: 0.8740 - mean_squared_error: 1.1542\n",
      "Epoch 00003: val_loss did not improve from 1.15612\n",
      "750156/750156 [==============================] - 84s 112us/sample - loss: 1.1549 - mean_absolute_error: 0.8739 - mean_squared_error: 1.1541 - val_loss: 1.1870 - val_mean_absolute_error: 0.8625 - val_mean_squared_error: 1.1862\n",
      "Epoch 4/100\n",
      "750080/750156 [============================>.] - ETA: 0s - loss: 1.1515 - mean_absolute_error: 0.8723 - mean_squared_error: 1.1507\n",
      "Epoch 00004: val_loss did not improve from 1.15612\n",
      "750156/750156 [==============================] - 83s 110us/sample - loss: 1.1515 - mean_absolute_error: 0.8723 - mean_squared_error: 1.1507 - val_loss: 1.1700 - val_mean_absolute_error: 0.8907 - val_mean_squared_error: 1.1692\n",
      "Epoch 5/100\n",
      "749568/750156 [============================>.] - ETA: 0s - loss: 1.1490 - mean_absolute_error: 0.8709 - mean_squared_error: 1.1483\n",
      "Epoch 00005: val_loss improved from 1.15612 to 1.14361, saving model to ./model/deepcin.h5\n",
      "750156/750156 [==============================] - 83s 111us/sample - loss: 1.1489 - mean_absolute_error: 0.8709 - mean_squared_error: 1.1482 - val_loss: 1.1436 - val_mean_absolute_error: 0.8735 - val_mean_squared_error: 1.1429\n",
      "Epoch 6/100\n",
      "750080/750156 [============================>.] - ETA: 0s - loss: 1.1470 - mean_absolute_error: 0.8699 - mean_squared_error: 1.1463\n",
      "Epoch 00006: val_loss improved from 1.14361 to 1.14144, saving model to ./model/deepcin.h5\n",
      "750156/750156 [==============================] - 83s 111us/sample - loss: 1.1469 - mean_absolute_error: 0.8699 - mean_squared_error: 1.1462 - val_loss: 1.1414 - val_mean_absolute_error: 0.8687 - val_mean_squared_error: 1.1408\n",
      "Epoch 7/100\n",
      "750080/750156 [============================>.] - ETA: 0s - loss: 1.1457 - mean_absolute_error: 0.8694 - mean_squared_error: 1.1450\n",
      "Epoch 00007: val_loss did not improve from 1.14144\n",
      "750156/750156 [==============================] - 83s 111us/sample - loss: 1.1457 - mean_absolute_error: 0.8694 - mean_squared_error: 1.1450 - val_loss: 1.1419 - val_mean_absolute_error: 0.8730 - val_mean_squared_error: 1.1412\n",
      "Epoch 8/100\n",
      "749824/750156 [============================>.] - ETA: 0s - loss: 1.1445 - mean_absolute_error: 0.8687 - mean_squared_error: 1.1438\n",
      "Epoch 00008: val_loss did not improve from 1.14144\n",
      "750156/750156 [==============================] - 83s 111us/sample - loss: 1.1445 - mean_absolute_error: 0.8687 - mean_squared_error: 1.1438 - val_loss: 1.1445 - val_mean_absolute_error: 0.8773 - val_mean_squared_error: 1.1438\n",
      "Epoch 9/100\n",
      "749824/750156 [============================>.] - ETA: 0s - loss: 1.1435 - mean_absolute_error: 0.8684 - mean_squared_error: 1.1428\n",
      "Epoch 00009: val_loss did not improve from 1.14144\n",
      "750156/750156 [==============================] - 83s 111us/sample - loss: 1.1434 - mean_absolute_error: 0.8684 - mean_squared_error: 1.1427 - val_loss: 1.1451 - val_mean_absolute_error: 0.8734 - val_mean_squared_error: 1.1444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f18b45b1400>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "checkpoint_path = \"./model/deepcin.h5\"\n",
    "cp_callback = keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                                              save_weights_only=True,\n",
    "                                              save_best_only=True,\n",
    "                                              verbose=1)\n",
    "\n",
    "model.fit(\n",
    "    [train_x_genres, train_x_gender, train_x_age, train_x_occupationid], train_y,\n",
    "    epochs=100, \n",
    "    validation_data=([test_x_genres, test_x_gender, test_x_age, test_x_occupationid], test_y,),\n",
    "    batch_size=256, shuffle=True,\n",
    "    callbacks=[early_stopping, cp_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
