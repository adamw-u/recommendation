{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先附上个论文地址：https://arxiv.org/pdf/1703.04247.pdf  \n",
    "会了fm，感觉这个超简单，就是：  \n",
    "$$\\hat{y}=\\operatorname{sigmoid}\\left(y_{F M}+y_{D N N}\\right)$$\n",
    "不过fm和dnn的特征是一样的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/baogong/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./util/')\n",
    "from utils import load_data_embdding \n",
    "\n",
    "users, movies, ratings = load_data_embdding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.merge(ratings.drop(columns = ['timestamp'],axis = 1), movies, how = 'left', on = 'movieid')\n",
    "data = pd.merge(data1, users, how = 'left', on = 'userid')\n",
    "\n",
    "X = data.drop(columns = ['userid', 'movieid', 'title', 'rating'])\n",
    "Y = data['rating'].values\n",
    "#genres, gender, age, occupationid四个需要embedding的特征，可以分别emb也可以合并以后emb，这里分别做emb\n",
    "set_genres = []\n",
    "for i in movies.index:\n",
    "    set_genres += movies['genres'].iloc[i]\n",
    "set_genres = list(set(set_genres))\n",
    "dic_genres = dict([(j, i) for i,j in enumerate(set_genres)])\n",
    "dic_genres['UNK'] = len(dic_genres)\n",
    "X['genres'] = X['genres'].apply(lambda x: [dic_genres[i] for i in x])\n",
    "x_genres = keras.preprocessing.sequence.pad_sequences(list(X['genres'].values),\n",
    "                                                        value = dic_genres['UNK'],\n",
    "                                                        padding = 'post',\n",
    "                                                        maxlen = 6)\n",
    "\n",
    "\n",
    "dic_gender = {'F':0, 'M':1}\n",
    "X['gender'] = X['gender'].apply(lambda x: [dic_gender[i] for i in x])\n",
    "dic_age = {1:0, 56:1, 25:2, 45:3, 50:4, 35:5, 18:6}\n",
    "X['age'] = X['age'].apply(lambda x: [dic_age[x]])\n",
    "list_occ = list(pd.unique(data['occupationid']))\n",
    "dic_occ = dict([(j, i) for i,j in enumerate(list_occ)])\n",
    "X['occupationid'] = X['occupationid'].apply(lambda x: [dic_occ[x]])\n",
    "\n",
    "x_gender = list(X['gender'].values)\n",
    "x_age = list(X['age'].values)\n",
    "x_occupationid = list(X['occupationid'].values)\n",
    "\n",
    "\n",
    "train_x_genres, test_x_genres, train_y, test_y = train_test_split(np.array(x_genres), Y, random_state=11)\n",
    "train_x_gender, test_x_gender = train_test_split(np.array(x_gender), random_state=11)\n",
    "train_x_age, test_x_age = train_test_split(np.array(x_age), random_state=11)\n",
    "train_x_occupationid, test_x_occupationid = train_test_split(np.array(x_occupationid), random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_combine = keras.layers.GlobalAveragePooling1D()(embedding_combine) \n",
    "\n",
    "\n",
    "fm_layer = FM(1,4)(embedding_combine)\n",
    "##dnn\n",
    "dnn_layer = keras.layers.Dense(64, activation = 'relu')(embedding_combine)\n",
    "dnn_layer = keras.layers.BatchNormalization()(dnn_layer)\n",
    "dnn_layer = keras.layers.Dense(32, activation = 'relu')(dnn_layer)\n",
    "dnn_layer = keras.layers.BatchNormalization()(dnn_layer)\n",
    "dnn_layer = keras.layers.Dense(1)(dnn_layer)\n",
    "##deepfm\n",
    "outputs = keras.layers.average([fm_layer, dnn_layer])  #因为是做回归，就用了average，分类的话得add后再接Activation\n",
    "\n",
    "optimizer = keras.optimizers.RMSprop(learning_rate = 0.001)\n",
    "model = tf.keras.Model(inputs = [input_genres, input_gender, input_age, input_occ], outputs = [outputs])\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['mean_absolute_error', 'mean_squared_error'],\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./layers/')\n",
    "from layers import FM\n",
    "\n",
    "def deepfm():\n",
    "    input_genres = keras.layers.Input(shape=(6,), name=\"genres\")  \n",
    "    embedding_genres = keras.layers.Embedding(output_dim=16, input_dim=len(dic_genres), input_length=6)(input_genres)\n",
    "\n",
    "    input_gender = keras.layers.Input(shape=(1,), name=\"gender\")  \n",
    "    embedding_gender = keras.layers.Embedding(output_dim=16, input_dim=2, input_length=1)(input_gender)\n",
    "\n",
    "    input_age = keras.layers.Input(shape=(1,), name=\"age\")  \n",
    "    embedding_age = keras.layers.Embedding(output_dim=16, input_dim=7, input_length=1)(input_age)\n",
    "\n",
    "    input_occ = keras.layers.Input(shape=(1,), name=\"occupationid\")  \n",
    "    embedding_occ = keras.layers.Embedding(output_dim=16, input_dim=21, input_length=1)(input_occ)\n",
    "\n",
    "    embedding_combine = keras.layers.concatenate(inputs=[embedding_genres, embedding_gender, embedding_age,\n",
    "                                                        embedding_occ], axis=1)\n",
    "    embedding_combine = keras.layers.GlobalAveragePooling1D()(embedding_combine) \n",
    "    \n",
    "    \n",
    "    fm_layer = FM(1,4)(embedding_combine)\n",
    "    ##dnn\n",
    "    dnn_layer = keras.layers.Dense(64, activation = 'relu')(embedding_combine)\n",
    "    dnn_layer = keras.layers.BatchNormalization()(dnn_layer)\n",
    "    dnn_layer = keras.layers.Dense(32, activation = 'relu')(dnn_layer)\n",
    "    dnn_layer = keras.layers.BatchNormalization()(dnn_layer)\n",
    "    dnn_layer = keras.layers.Dense(1)(dnn_layer)\n",
    "    ##deepfm\n",
    "    outputs = keras.layers.average([fm_layer, dnn_layer])  #因为是做回归，就用了average，分类的话得add后再接Activation\n",
    "    \n",
    "    optimizer = keras.optimizers.RMSprop(learning_rate = 0.001)\n",
    "    model = tf.keras.Model(inputs = [input_genres, input_gender, input_age, input_occ], outputs = [outputs])\n",
    "    \n",
    "    model.compile(loss='mean_squared_error',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['mean_absolute_error', 'mean_squared_error'],\n",
    "             )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 750156 samples, validate on 250053 samples\n",
      "Epoch 1/100\n",
      "748288/750156 [============================>.] - ETA: 0s - loss: 2.0500 - mean_absolute_error: 1.0748 - mean_squared_error: 2.0500\n",
      "Epoch 00001: val_loss improved from inf to 1.40142, saving model to ./model/deepfm.h5\n",
      "750156/750156 [==============================] - 13s 17us/sample - loss: 2.0477 - mean_absolute_error: 1.0743 - mean_squared_error: 2.0477 - val_loss: 1.4014 - val_mean_absolute_error: 0.9858 - val_mean_squared_error: 1.4014\n",
      "Epoch 2/100\n",
      "749568/750156 [============================>.] - ETA: 0s - loss: 1.1686 - mean_absolute_error: 0.8808 - mean_squared_error: 1.1686\n",
      "Epoch 00002: val_loss improved from 1.40142 to 1.18276, saving model to ./model/deepfm.h5\n",
      "750156/750156 [==============================] - 12s 16us/sample - loss: 1.1685 - mean_absolute_error: 0.8808 - mean_squared_error: 1.1685 - val_loss: 1.1828 - val_mean_absolute_error: 0.8985 - val_mean_squared_error: 1.1828\n",
      "Epoch 3/100\n",
      "750080/750156 [============================>.] - ETA: 0s - loss: 1.1647 - mean_absolute_error: 0.8788 - mean_squared_error: 1.1647\n",
      "Epoch 00003: val_loss did not improve from 1.18276\n",
      "750156/750156 [==============================] - 12s 16us/sample - loss: 1.1646 - mean_absolute_error: 0.8788 - mean_squared_error: 1.1646 - val_loss: 1.2010 - val_mean_absolute_error: 0.9065 - val_mean_squared_error: 1.2010\n",
      "Epoch 4/100\n",
      "749568/750156 [============================>.] - ETA: 0s - loss: 1.1617 - mean_absolute_error: 0.8773 - mean_squared_error: 1.1617\n",
      "Epoch 00004: val_loss improved from 1.18276 to 1.16910, saving model to ./model/deepfm.h5\n",
      "750156/750156 [==============================] - 12s 16us/sample - loss: 1.1618 - mean_absolute_error: 0.8773 - mean_squared_error: 1.1618 - val_loss: 1.1691 - val_mean_absolute_error: 0.8866 - val_mean_squared_error: 1.1691\n",
      "Epoch 5/100\n",
      "748288/750156 [============================>.] - ETA: 0s - loss: 1.1595 - mean_absolute_error: 0.8763 - mean_squared_error: 1.1595\n",
      "Epoch 00005: val_loss improved from 1.16910 to 1.16527, saving model to ./model/deepfm.h5\n",
      "750156/750156 [==============================] - 12s 16us/sample - loss: 1.1596 - mean_absolute_error: 0.8763 - mean_squared_error: 1.1596 - val_loss: 1.1653 - val_mean_absolute_error: 0.8875 - val_mean_squared_error: 1.1653\n",
      "Epoch 6/100\n",
      "749824/750156 [============================>.] - ETA: 0s - loss: 1.1579 - mean_absolute_error: 0.8756 - mean_squared_error: 1.1579\n",
      "Epoch 00006: val_loss improved from 1.16527 to 1.15145, saving model to ./model/deepfm.h5\n",
      "750156/750156 [==============================] - 12s 16us/sample - loss: 1.1579 - mean_absolute_error: 0.8756 - mean_squared_error: 1.1579 - val_loss: 1.1514 - val_mean_absolute_error: 0.8737 - val_mean_squared_error: 1.1514\n",
      "Epoch 7/100\n",
      "747264/750156 [============================>.] - ETA: 0s - loss: 1.1568 - mean_absolute_error: 0.8750 - mean_squared_error: 1.1568\n",
      "Epoch 00007: val_loss did not improve from 1.15145\n",
      "750156/750156 [==============================] - 12s 16us/sample - loss: 1.1567 - mean_absolute_error: 0.8750 - mean_squared_error: 1.1567 - val_loss: 1.1610 - val_mean_absolute_error: 0.8883 - val_mean_squared_error: 1.1610\n",
      "Epoch 8/100\n",
      "750080/750156 [============================>.] - ETA: 0s - loss: 1.1555 - mean_absolute_error: 0.8744 - mean_squared_error: 1.1555\n",
      "Epoch 00008: val_loss did not improve from 1.15145\n",
      "750156/750156 [==============================] - 12s 16us/sample - loss: 1.1555 - mean_absolute_error: 0.8744 - mean_squared_error: 1.1555 - val_loss: 1.1661 - val_mean_absolute_error: 0.8836 - val_mean_squared_error: 1.1661\n",
      "Epoch 9/100\n",
      "749824/750156 [============================>.] - ETA: 0s - loss: 1.1547 - mean_absolute_error: 0.8739 - mean_squared_error: 1.1547\n",
      "Epoch 00009: val_loss did not improve from 1.15145\n",
      "750156/750156 [==============================] - 12s 16us/sample - loss: 1.1547 - mean_absolute_error: 0.8739 - mean_squared_error: 1.1547 - val_loss: 1.1524 - val_mean_absolute_error: 0.8752 - val_mean_squared_error: 1.1524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdca70c1390>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "checkpoint_path = \"./model/deepfm.h5\"\n",
    "cp_callback = keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                                              save_weights_only=True,\n",
    "                                              save_best_only=True,\n",
    "                                              verbose=1)\n",
    "model = deepfm()\n",
    "\n",
    "model.fit(\n",
    "    [train_x_genres, train_x_gender, train_x_age, train_x_occupationid], train_y,\n",
    "    epochs=100, \n",
    "    validation_data=([test_x_genres, test_x_gender, test_x_age, test_x_occupationid], test_y,),\n",
    "    batch_size=256, shuffle=True,\n",
    "    callbacks=[early_stopping, cp_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "genres (InputLayer)             [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gender (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "age (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "occupationid (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 6, 16)        304         genres[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 1, 16)        32          gender[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 1, 16)        112         age[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 1, 16)        336         occupationid[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 9, 16)        0           embedding_4[0][0]                \n",
      "                                                                 embedding_5[0][0]                \n",
      "                                                                 embedding_6[0][0]                \n",
      "                                                                 embedding_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 16)           0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64)           1088        global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 64)           256         dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 32)           2080        batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32)           128         dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "fm_1 (FM)                       (None, 1)            81          global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            33          batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_1 (Average)             (None, 1)            0           fm_1[0][0]                       \n",
      "                                                                 dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,450\n",
      "Trainable params: 4,258\n",
      "Non-trainable params: 192\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
